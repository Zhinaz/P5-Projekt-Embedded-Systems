\section{Algorithm design} \label{sec:algorithm-design}

In order to solve the \emph{travelling salesman problem}, as described in \secref{sec:problem-description}, a heuristic is needed. Since it is not feasible to solve the problem of finding the optimal path, an algorithm that provides an acceptable solution will be chosen instead.

Two algorithms have been proposed and designed in this project: one is more intelligent and takes all the relative distances between the objects into account, while the other is very reactive. These two algorithms are, respectively, the \emph{nearest neighbour (NN) algorithm} and the \emph{next-in-view (NIV) algorithm}.


\subsection{Nearest neighbour algorithm} \label{sec:nn-algorithm}
The NN-algorithm starts by doing a 360 degrees turn while scanning the nearby area around it for objects. The distance and angle for each object are saved and when the robot is done scanning, a route will be calculated using trigonometry and the NN-algorithm concepts. These calculations will result in an array of instructions containing distances and angles. Each instruction will take the robot from the current position to the next object following the calculated route. The robot should scan after completing the route, to ensure that all objects has been collected, in case it didn't collect all of the objects. The \projname{} computes the entire route before moving.

The algorithm uses trigonometry to select the next object, by using the current position, the starting position and the position of the next object. These positions are in relation to the starting position, where all the objects positions were found. The amount of degrees the \projname{} must turn, in order to get to the same heading as the next object, is saved as instructions, along with the distance that needs to be travelled in order to get to it. 

These instructions must then be followed after the route has been calculated. \figref{fig:object_navigation_first} shows a situation where all the objects have been spotted, and now the \projname{} must decide which object that should be collected first. At this point the shortest object is easy to calculate, as the distance to all objects, from the starting position, is already known, based on information from the ultrasonic sensor. The shortest distance overall is found, and saved along with the heading, and the object associated to this is remembered, and marked as added to the instructions, to remove this from consideration when finding the path to the next objects. Another set of instructions is used to ensure that the \projname{} is pointing back, at the starting position. This is used to ease the calculations of the following objects. 

\begin{figure}[H]
     \center{\includegraphics[width=\textwidth]
     {graphics/ObjectNavigationFirst.pdf}}
     \caption{\label{fig:object_navigation_first} First object to be collected.}
\end{figure}

Now that the first object has been scheduled to be collected, the NN-algorithm uses trigonometry to find the shortest distance to the next object, and calculates the angles that is needed to turn, to face the next object. The distance to all the other objects must be calculated, in order to find the closest one. To increase the understanding, the state of the world is represented in \figref{fig:object_navigation_iteration}, where the actions to collect the first object has been applied and reflected in the figure. From this point, the distance to the remaining objects is calculated, using the formula:
\begin{equation}
a = \sqrt{ b^2 + c^2 - 2*b*c*cos(A) } \label{equation:a}
\end{equation}

But for this, the A angle is needed. This is calculated from the spotted angles during the search. The formula for calculating A is:
\begin{equation}
A = (Object~currently~at~spotted~angle) - (Object~closest~spotted~angle) \label{equation:AAngle}
\end{equation}

With the same method as the first object, the object with the shortest distance, from the current object, is found and the object number is saved. Now the heading to the closest object must be calculated, and this is the angle calculated by the formula:
\begin{equation}
B = cos^{-1}((a^2 + c^2 - b^2)/(2*a*c)) \label{equation:B}
\end{equation}

This provides the angle that must be turned in order to face the next object. In \figref{fig:object_navigation_iteration} the \projname{} is pointed towards the starting position, and the angle that must be turned is calculated from \equref{equation:B}. The current heading added/subtracted (depending on the position) with the angle provides the heading to the next object. This angle is added to the instructions along with the distance. Then the final angle of the triangle is calculated, which is used to turn the \projname{} towards the starting position again. The final angle is calculated with the formula:
\begin{equation}
C = 180 - A - B \label{equation:C}
\end{equation}

In order to point the \projname{} at the starting position again, the current heading is subtracted with (180 - C), where C is found by \equref{equation:C}. This process has provided the route to the next object, and the instructions to turn the \projname{} back, facing the starting position. The iterative step, that uses trigonometry to calculate the route to the next object, is executed for the remaining objects that were spotted.

\begin{figure}[H]
     \center{\includegraphics[width=\textwidth]
     {graphics/ObjectNavigationIteration.pdf}}
     \caption{\label{fig:object_navigation_iteration} Iteration of objects to be collected.}
\end{figure}


\subsection{Next-in-view algorithm} \label{sec:niv-algorithm}
An important property of the Next-in-view algorithm, is that it does not do any calculations prior to moving for objects, like the NN-algorithm. However it still relies a lot on the ultrasonic sensor, but in a different way. Instead of using the ultrasonic sensor to map the objects during the initial scan until all objects has been found, it uses the inputs from the sensor until all objects have been collected.

\begin{figure}[H]
     \center{\includegraphics[width=\textwidth]
     {graphics/ObjectNavigationNIV.pdf}}
     \caption{\label{fig:object_navigation_niv} Start-up using the Next-in-view algorithm}
\end{figure}

At start-up the robot starts turning until it spots an object with the ultrasonic sensor, as seen in \figref{fig:object_navigation_niv}. It then drives towards it until the object is within grabbing distance of the claw. The object will be picked up and the \projname{} continues to search for objects, as seen in \figref{fig:object_navigation_niv2}

\begin{figure}[H]
     \center{\includegraphics[width=\textwidth]
     {graphics/ObjectNavigationNIV2.pdf}}
     \caption{\label{fig:object_navigation_niv2} Searching for the next object}
\end{figure} 

Because the ultrasonic sensors view is a cone, as described in \secref{sec:hardware}, a case may arise where the robot is not driving straight towards the object. And as it gets closer, it might lose the object as it gets out of the view of the sensor.

In this case, a small routine will be initiated, where the robot will turn a little to the right, followed by a little to the left, constantly scanning for objects, while slowly increasing the angles turned to scan an increasingly larger range. When an object is spotted again, the robot continues to move towards it. When the object has been collected, the robot starts turning until it finds a new object and the entire process continues until every object has been found.


\subsection{Algorithm comparison} \label{sec:algorithm-desc}

The shortest route between the objects can be brute forced by trying out every single possible route between the start position and all of the objects. This would have a calculation time of $\mathcal{O}(n!)$, which means that with every object added, the running time greatly increases. This gives the robot problems when calculating the shortest route, if the amount of objects exceeds a certain number, due to its limited processing power. If there are 9 objects for instance, the number of different paths to check exceeds 360,000.  

A faster, but less distance-efficient algorithm is the NN-algorithm. The algorithm calculates a route based on which objects are closest together. This means that the distance to all the points are calculated from the starting point and the shortest distance is chosen. This is then repeated from the new point, but this time it does not include the objects from previously visited points. This results in a worst case calculation time of $\mathcal{O}(n^2)$, although as the number of remaining objects decreases for each object added to the route, described by $\sum\limits_{i=n}^n i = i - 1$, the calculation time decreases for each object. Compared to the brute force approach, this algorithm uses only a fraction of the time to compute the result. 

An algorithm that doesn't spend time on calculations prior to moving for objects is the next-in-view algorithm. This algorithm has a number of issues connected to it, which may reduce its performance, however in smaller cases with less than ten objects, its completion speed is close to the NN-algorithm. This is based purely on a theoretical test calculation.

\begin{figure}[H]
     \center{\includegraphics[width=\textwidth]
     {graphics/AlgorithmExamples2.pdf}}
     \caption{\label{fig:algorithm-example} Example of the NN-algorithm, the optimal solution, and next-in-view algorithm.}
\end{figure}

\figref{fig:algorithm-example} shows three solutions to the problem. The top right graph is the optimal solution, which is only used to compare the results from the two other algorithms. Top left is the NN-algorithm, and in the bottom the next-in-view algorithm. The robot starts its route at position \emph{S}, facing north (0 degrees) for these examples. The objects are named in order as they are first detected, if scanning clockwise. The algorithms result in the routes shown on the figure.

The different algorithms result in the routes shown in \figref{fig:algorithm-example}, and have following lengths:
\begin{itemize}
\item Optimal: 33.5 units
\item Nearest neighbour algorithm: 35.75 units
\item Next-in-view: 38.55 units
\end{itemize}

In the average case, the difference between the NN-algorithm and the NIV solutions would be larger if there were more objects to consider. However for these smaller cases, the difference is almost negligible. It should be noted, that this does not describe the time spent, only the distance travelled: rotation to scan for objects, for both algorithms, takes different amounts of time depending on the case. This is not accounted for here.

Due to the limitations of the LEGO NXT brick and the complexity of the problem, finding the optimal solution was ruled out as a possibility. The NN-algorithm maps all objects in the environment, and constructs a route to all the objects before it begins collecting them. The NIV-algorithm is very ad hoc in nature, in that it simply goes for the first object that the robot spots after each scanning cycle is initiated. 

The NN-algorithm is expected to yield the most efficient results, however based on the hardware test of the ultrasonic sensor in \secref{sec:ultrasonic_sensor}, it was deemed unlikely that it would work in practice, since it heavily relies on accurate information about the location of objects in the environment. Due to this, the NN-algorithm was designed in the case that it would work in practice, however the NIV-algorithm was designed and implemented first, as insurance that the robot would be able to complete its task, however not as efficiently.

As mentioned in the test case from \secref{sec:nn-algorithm}, the difference between the two algorithms' distance were nearly insignificant. 

Neither algorithm ensures that the entirety of the environment has been checked for the presence for objects. This problem, as mentioned in \secref{sec:problem-description}, is complex and is not the focus of the project. The \projname{} will terminate once all objects have been found, and if it cannot find all of them, it will keep searching. This is not optimal, and it is obvious that the algorithms described here would have to be expanded to work in a real scenario.